{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3561c56",
   "metadata": {},
   "source": [
    "# DEEP NEURAL NETWORKS - ASSIGNMENT 2: CNN FOR IMAGE CLASSIFICATION\n",
    "\n",
    "## Convolutional Neural Networks: Custom Implementation vs Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7be6ad",
   "metadata": {},
   "source": [
    "STUDENT INFORMATION (REQUIRED - DO NOT DELETE)\n",
    "\n",
    "BITS ID: [Enter your BITS ID here - e.g., 2025AA1234]\n",
    "\n",
    "Name: [Enter your full name here - e.g., JOHN DOE]\n",
    "\n",
    "Email: [Enter your email]\n",
    "\n",
    "Date: [Submission date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be209f24",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from PIL import Image, UnidentifiedImageError # Added UnidentifiedImageError for robust cleaning\n",
    "import shutil # For copying files\n",
    "\n",
    "# Deep learning frameworks\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet50, VGG16\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Configure TensorFlow to dynamically allocate GPU memory\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs configured for memory growth.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU detected by TensorFlow. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8162fad",
   "metadata": {},
   "source": [
    "### 1.1 Dataset Selection and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e736527",
   "metadata": {},
   "source": [
    "# --- Data Preparation: Download, Extract, Clean, and Organize ---\n",
    "# This section downloads data from Kaggle, then organizes and cleans it.\n",
    "\n",
    "# Step 0: Initial Cleanup of any previous data directories\n",
    "print(\"\\n--- Step 0: Initial Cleanup ---\")\n",
    "!rm -rf PetImages # Remove any pre-existing main data directory\n",
    "!rm -rf Cleaned_PetImages_For_Training # Remove any pre-existing cleaned data directory\n",
    "!rm -rf /content/dogs-vs-cats.zip # Remove original downloaded zip\n",
    "!rm -rf /content/train.zip\n",
    "!rm -rf /content/test1.zip\n",
    "!rm -rf /content/kaggle_download # Remove any temporary extraction folders\n",
    "print(\"Cleanup complete.\")\n",
    "\n",
    "# Step 1: Kaggle API Setup and Download\n",
    "print(\"\\n--- Step 1: Kaggle API Setup and Download ---\")\n",
    "!pip install -q kaggle # -q for quiet install\n",
    "!mkdir -p ~/.kaggle\n",
    "# IMPORTANT: Ensure kaggle.json is uploaded to Colab files sidebar BEFORE running this\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "RAW_DOWNLOAD_DIR = '/content/kaggle_download' # A temporary dir for initial download\n",
    "os.makedirs(RAW_DOWNLOAD_DIR, exist_ok=True)\n",
    "print(f\"Downloading data from Kaggle to {RAW_DOWNLOAD_DIR}...\")\n",
    "!kaggle competitions download -c dogs-vs-cats -p {RAW_DOWNLOAD_DIR}\n",
    "print(\"Kaggle download complete.\")\n",
    "\n",
    "# Step 2: Extracting train.zip\n",
    "print(\"\\n--- Step 2: Extracting train.zip ---\")\n",
    "# The train.zip contains a 'train' folder which has all images\n",
    "!unzip -qq {RAW_DOWNLOAD_DIR}/train.zip -d {RAW_DOWNLOAD_DIR}\n",
    "print(\"Extraction of train.zip complete.\")\n",
    "\n",
    "# Define the path to the raw extracted images (e.g., /content/kaggle_download/train)\n",
    "RAW_IMAGES_FOLDER = os.path.join(RAW_DOWNLOAD_DIR, 'train')\n",
    "if not os.path.exists(RAW_IMAGES_FOLDER):\n",
    "    print(f\"ERROR: Raw images folder not found at {RAW_IMAGES_FOLDER}. Check extraction path.\")\n",
    "    raise FileNotFoundError(f\"Expected raw images at {RAW_IMAGES_FOLDER} but it doesn't exist.\")\n",
    "\n",
    "# Step 3: Set up NEW, CLEAN directories for training (where only verified good images will reside)\n",
    "CLEANED_DATASET_BASE = 'Cleaned_PetImages_For_Training' # New folder for processed data\n",
    "cleaned_train_dir = os.path.join(CLEANED_DATASET_BASE, 'Train')\n",
    "cleaned_test_dir = os.path.join(CLEANED_DATASET_BASE, 'Test')\n",
    "\n",
    "os.makedirs(os.path.join(cleaned_train_dir, 'Cat'), exist_ok=True)\n",
    "os.makedirs(os.path.join(cleaned_train_dir, 'Dog'), exist_ok=True)\n",
    "os.makedirs(os.path.join(cleaned_test_dir, 'Cat'), exist_ok=True)\n",
    "os.makedirs(os.path.join(cleaned_test_dir, 'Dog'), exist_ok=True)\n",
    "print(f\"Created new directories for cleaned data at: {CLEANED_DATASET_BASE}\")\n",
    "\n",
    "\n",
    "# Step 4: Meticulous Cleaning and Copying to New Directories (No Deletion of originals)\n",
    "print(\"\\n--- Step 4: Verifying and Copying Good Images to Cleaned Directories ---\")\n",
    "\n",
    "good_image_paths_by_category = {'Cat': [], 'Dog': []}\n",
    "skipped_file_count = 0\n",
    "verified_file_count = 0\n",
    "\n",
    "print(f\"Scanning and verifying images from: {RAW_IMAGES_FOLDER}\")\n",
    "all_raw_image_files = [f for f in os.listdir(RAW_IMAGES_FOLDER) if os.path.isfile(os.path.join(RAW_IMAGES_FOLDER, f))]\n",
    "\n",
    "for img_name in all_raw_image_files:\n",
    "    img_path_raw = os.path.join(RAW_IMAGES_FOLDER, img_name)\n",
    "    \n",
    "    category = None\n",
    "    if img_name.lower().startswith('cat'): category = 'Cat'\n",
    "    elif img_name.lower().startswith('dog'): category = 'Dog'\n",
    "    else: continue # Skip files that are neither cat nor dog (e.g., desktop.ini or other non-image files)\n",
    "\n",
    "    try:\n",
    "        # Check for zero-byte files\n",
    "        if os.path.getsize(img_path_raw) == 0:\n",
    "            skipped_file_count += 1\n",
    "            continue\n",
    "        \n",
    "        with Image.open(img_path_raw) as img:\n",
    "            img.verify() # Verify file integrity\n",
    "            img.convert('RGB') # Forces full loading and conversion\n",
    "        \n",
    "        # If all steps above succeed, the image is considered good\n",
    "        good_image_paths_by_category[category].append(img_path_raw)\n",
    "        verified_file_count += 1\n",
    "\n",
    "    except (IOError, SyntaxError, UnidentifiedImageError, AttributeError) as e:\n",
    "        skipped_file_count += 1\n",
    "        # print(f\"  --> Skipping corrupted/unidentifiable image: {img_path_raw} - Error: {type(e).__name__}: {e}\") # Uncomment for debugging\n",
    "        pass # Do not delete, just skip\n",
    "    \n",
    "    if (verified_file_count + skipped_file_count) % 1000 == 0: # Progress indicator\n",
    "        print(f\"Processed {verified_file_count + skipped_file_count} images. Verified: {verified_file_count}, Skipped: {skipped_file_count}.\")\n",
    "\n",
    "print(f\"\\n--- Finished checking all raw images. ---\")\n",
    "print(f\"Total VERIFIED images: {verified_file_count}\")\n",
    "print(f\"Total SKIPPED images (zero-byte/corrupted): {skipped_file_count}\")\n",
    "print(f\"Verified good Cat images found: {len(good_image_paths_by_category['Cat'])}\")\n",
    "print(f\"Verified good Dog images found: {len(good_image_paths_by_category['Dog'])}\")\n",
    "\n",
    "\n",
    "# Step 5: Split and Copy ONLY the good images to the new structure\n",
    "final_train_samples = 0\n",
    "final_test_samples = 0\n",
    "split_ratio = 0.9 # This split is applied to the combined good images\n",
    "\n",
    "print(\"\\n--- Step 5: Copying good images to final Train/Test directories ---\")\n",
    "for category, img_list in good_image_paths_by_category.items():\n",
    "    random.shuffle(img_list) # Shuffle good images before splitting\n",
    "    split_idx = int(len(img_list) * split_ratio)\n",
    "    \n",
    "    train_images = img_list[:split_idx]\n",
    "    test_images = img_list[split_idx:]\n",
    "    \n",
    "    # Copy to cleaned_train_dir\n",
    "    print(f\"Copying {len(train_images)} train images for {category}...\")\n",
    "    for img_path_src in train_images:\n",
    "        img_name = os.path.basename(img_path_src)\n",
    "        shutil.copy(img_path_src, os.path.join(cleaned_train_dir, category, img_name))\n",
    "    final_train_samples += len(train_images)\n",
    "\n",
    "    # Copy to cleaned_test_dir\n",
    "    print(f\"Copying {len(test_images)} test images for {category}...\")\n",
    "    for img_path_src in test_images:\n",
    "        img_name = os.path.basename(img_path_src)\n",
    "        shutil.copy(img_path_src, os.path.join(cleaned_test_dir, category, img_name))\n",
    "    final_test_samples += len(test_images)\n",
    "\n",
    "print(f\"\\nFinal total training samples: {final_train_samples}\")\n",
    "print(f\"Final total testing samples: {final_test_samples}\")\n",
    "print(\"--- Cleaning and Copying Complete ---\")\n",
    "\n",
    "# Step 6: Clean up the raw downloaded and extracted data to save space\n",
    "print(\"\\n--- Step 6: Cleaning up raw download/extraction directories ---\")\n",
    "!rm -rf {RAW_DOWNLOAD_DIR}\n",
    "print(\"Raw data cleanup complete.\")\n",
    "\n",
    "\n",
    "# --- Dataset Metadata (using the final, cleaned counts) ---\n",
    "dataset_name = \"Cats vs Dogs (Kaggle Download, Cleaned & Structured)\"\n",
    "dataset_source = \"Kaggle\"\n",
    "n_samples = final_train_samples + final_test_samples\n",
    "n_classes = 2 # Fixed for Cats vs Dogs\n",
    "\n",
    "n_cat_final_train = len(os.listdir(os.path.join(cleaned_train_dir, 'Cat')))\n",
    "n_dog_final_train = len(os.listdir(os.path.join(cleaned_train_dir, 'Dog')))\n",
    "n_cat_final_test = len(os.listdir(os.path.join(cleaned_test_dir, 'Cat')))\n",
    "n_dog_final_test = len(os.listdir(os.path.join(cleaned_test_dir, 'Dog')))\n",
    "samples_per_class = f\"Train (Cat): {n_cat_final_train}, (Dog): {n_dog_final_train} | Test (Cat): {n_cat_final_test}, (Dog): {n_dog_final_test}\"\n",
    "\n",
    "# Image shape (adjusted for memory management)\n",
    "image_shape = [150, 150, 3] # Using 150x150 as a balance. Can reduce to 64x64 if OOM occurs.\n",
    "problem_type = \"classification\"\n",
    "primary_metric = \"accuracy\"\n",
    "metric_justification = \"\"\"\n",
    "Accuracy is chosen as the primary metric because the Cats vs Dogs dataset is relatively balanced.\n",
    "In a balanced dataset, accuracy provides a good overall measure of the model's performance,\n",
    "indicating the proportion of correctly classified images among all images.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- Updated DATASET INFORMATION ---\")\n",
    "print(f\"Dataset: {dataset_name}\")\n",
    "print(f\"Source: {dataset_source}\")\n",
    "print(f\"Total Samples: {n_samples}\")\n",
    "print(f\"Number of Classes: {n_classes}\")\n",
    "print(f\"Samples per Class: {samples_per_class}\")\n",
    "print(f\"Image Shape: {image_shape}\")\n",
    "print(f\"Primary Metric: {primary_metric}\")\n",
    "print(f\"Metric Justification: {metric_justification}\")\n",
    "\n",
    "# Required: Document your split\n",
    "train_test_ratio = f\"{round(final_train_samples/n_samples*100)}/{round(final_test_samples/n_samples*100)}\"\n",
    "print(f\"\\nTrain/Test Split: {train_test_ratio}\")\n",
    "print(f\"Training Samples: {final_train_samples}\")\n",
    "print(f\"Test Samples: {final_test_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d410ae6",
   "metadata": {},
   "source": [
    "### 1.2 Data Exploration and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ff05ae",
   "metadata": {},
   "source": [
    "# --- ImageDataGenerator Setup ---\n",
    "IMG_HEIGHT, IMG_WIDTH = image_shape[0], image_shape[1]\n",
    "BATCH_SIZE = 8 # Adjusted for memory management. Can try 4 if 8 fails.\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# IMPORTANT: Point generators to the CLEANED_DATASET_BASE directories\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    cleaned_train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    cleaned_test_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    seed=SEED,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# --- Class Distribution Plotting ---\n",
    "class_labels = list(train_generator.class_indices.keys())\n",
    "\n",
    "train_counts_plot = {label: 0 for label in class_labels}\n",
    "num_batches_train_plot = len(train_generator)\n",
    "if num_batches_train_plot == 0:\n",
    "    print(\"Warning: train_generator is empty for plotting. No training data.\")\n",
    "else:\n",
    "    for i in range(num_batches_train_plot):\n",
    "        try:\n",
    "            _, labels = train_generator[i]\n",
    "            for label_one_hot in labels:\n",
    "                class_index = np.argmax(label_one_hot)\n",
    "                if class_index < len(class_labels):\n",
    "                    train_counts_plot[class_labels[class_index]] += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error during train_generator iteration for plotting at batch {i}: {e}\")\n",
    "            break\n",
    "train_counts_plot = {k:v for k,v in train_counts_plot.items() if v>0}\n",
    "\n",
    "test_counts_plot = {label: 0 for label in class_labels}\n",
    "num_batches_test_plot = len(test_generator)\n",
    "if num_batches_test_plot == 0:\n",
    "    print(\"Warning: test_generator is empty for plotting. No test data.\")\n",
    "else:\n",
    "    for i in range(num_batches_test_plot):\n",
    "        try:\n",
    "            _, labels = test_generator[i]\n",
    "            for label_one_hot in labels:\n",
    "                class_index = np.argmax(label_one_hot)\n",
    "                if class_index < len(class_labels):\n",
    "                    test_counts_plot[class_labels[class_index]] += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error during test_generator iteration for plotting at batch {i}: {e}\")\n",
    "            break\n",
    "test_counts_plot = {k:v for k,v in test_counts_plot.items() if v>0}\n",
    "\n",
    "\n",
    "if not train_counts_plot:\n",
    "    print(\"Warning: No data to plot for Training Class Distribution.\")\n",
    "else:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x=list(train_counts_plot.keys()), y=list(train_counts_plot.values()))\n",
    "    plt.title('Training Class Distribution')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "if not test_counts_plot:\n",
    "    print(\"Warning: No data to plot for Test Class Distribution.\")\n",
    "else:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x=list(test_counts_plot.keys()), y=list(test_counts_plot.values()))\n",
    "    plt.title('Test Class Distribution')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709a1426",
   "metadata": {},
   "source": [
    "### 2.1 Custom CNN Architecture Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b21d7",
   "metadata": {},
   "source": [
    "def build_custom_cnn(input_shape, n_classes):\n",
    "    \"\"\"\n",
    "    Build custom CNN architecture\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # First convolutional block\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # Second convolutional block\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    # Third convolutional block\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # Global Average Pooling (MANDATORY)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Dense layers for classification head\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(n_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Create model instance\n",
    "custom_cnn = build_custom_cnn(image_shape, n_classes)\n",
    "\n",
    "# Compile model\n",
    "custom_cnn.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "custom_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79ff01f",
   "metadata": {},
   "source": [
    "### 2.2 Train Custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1017613c",
   "metadata": {},
   "source": [
    "print(\"\\nCUSTOM CNN TRAINING\")\n",
    "# Track training time\n",
    "custom_cnn_start_time = time.time()\n",
    "\n",
    "EPOCHS = 20 # Can be adjusted\n",
    "\n",
    "# History object to store training metrics\n",
    "history_custom_cnn = custom_cnn.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=test_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    validation_steps=test_generator.samples // BATCH_SIZE,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "custom_cnn_training_time = time.time() - custom_cnn_start_time\n",
    "\n",
    "# REQUIRED: Track initial and final loss\n",
    "custom_cnn_initial_loss = float(history_custom_cnn.history['loss'][0])\n",
    "custom_cnn_final_loss = float(history_custom_cnn.history['loss'][-1])\n",
    "\n",
    "print(f\"Training completed in {custom_cnn_training_time:.2f} seconds\")\n",
    "print(f\"Initial Loss: {custom_cnn_initial_loss:.4f}\")\n",
    "print(f\"Final Loss: {custom_cnn_final_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0090d1",
   "metadata": {},
   "source": [
    "### 2.3 Evaluate Custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7796b66",
   "metadata": {},
   "source": [
    "print(\"\\nCUSTOM CNN EVALUATION\")\n",
    "\n",
    "# Get predictions\n",
    "y_pred_probs_cnn = custom_cnn.predict(test_generator, steps=(test_generator.samples // BATCH_SIZE) + 1)\n",
    "y_pred_cnn = np.argmax(y_pred_probs_cnn, axis=1)\n",
    "\n",
    "y_true_cnn = test_generator.classes[:len(y_pred_cnn)]\n",
    "\n",
    "\n",
    "# Calculate all 4 metrics\n",
    "custom_cnn_accuracy = float(accuracy_score(y_true_cnn, y_pred_cnn))\n",
    "custom_cnn_precision = float(precision_score(y_true_cnn, y_pred_cnn, average='macro', zero_division=0))\n",
    "custom_cnn_recall = float(recall_score(y_true_cnn, y_pred_cnn, average='macro', zero_division=0))\n",
    "custom_cnn_f1 = float(f1_score(y_true_cnn, y_pred_cnn, average='macro', zero_division=0))\n",
    "\n",
    "print(\"\\nCustom CNN Performance:\")\n",
    "print(f\"Accuracy:  {custom_cnn_accuracy:.4f}\")\n",
    "print(f\"Precision: {custom_cnn_precision:.4f}\")\n",
    "print(f\"Recall:    {custom_cnn_recall:.4f}\")\n",
    "print(f\"F1-Score:  {custom_cnn_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eac1b9f",
   "metadata": {},
   "source": [
    "### 2.4 Visualize Custom CNN Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24cb2d4",
   "metadata": {},
   "source": [
    "# Plot training loss curve\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_custom_cnn.history['loss'], label='Train Loss')\n",
    "plt.plot(history_custom_cnn.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Custom CNN Loss Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_custom_cnn.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history_custom_cnn.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Custom CNN Accuracy Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm_cnn = confusion_matrix(y_true_cnn, y_pred_cnn)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_cnn, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.title('Custom CNN Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Show sample predictions\n",
    "def plot_sample_predictions(generator, model, class_labels, num_samples=5):\n",
    "    # Get one batch of images and labels\n",
    "    x, y_true_one_hot = next(generator)\n",
    "    \n",
    "    # Adapt samples_to_plot to the actual size of the batch received\n",
    "    actual_batch_size = x.shape[0]\n",
    "    samples_to_plot = min(num_samples, actual_batch_size)\n",
    "    \n",
    "    y_true = np.argmax(y_true_one_hot, axis=1)\n",
    "    y_pred_probs = model.predict(x)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    for i in range(samples_to_plot): # Loop only for available samples\n",
    "        plt.subplot(1, samples_to_plot, i + 1) # Adjust subplot grid to actual samples shown\n",
    "        plt.imshow(x[i])\n",
    "        \n",
    "        true_label_text = class_labels[y_true[i]] if y_true[i] < len(class_labels) else f\"Unknown ({y_true[i]})\"\n",
    "        pred_label_text = class_labels[y_pred[i]] if y_pred[i] < len(class_labels) else f\"Unknown ({y_pred[i]})\"\n",
    "\n",
    "        plt.title(f\"True: {true_label_text}\\nPred: {pred_label_text}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nSample Custom CNN Predictions:\")\n",
    "plot_sample_predictions(test_generator, custom_cnn, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11c6095",
   "metadata": {},
   "source": [
    "### 3.1 Load Pre-trained Model and Modify Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b730caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRANSFER LEARNING IMPLEMENTATION\")\n",
    "\n",
    "pretrained_model_name = \"ResNet50\" # Chosen pre-trained model\n",
    "\n",
    "def build_transfer_learning_model(base_model_name, input_shape, n_classes):\n",
    "    \"\"\"\n",
    "    Build transfer learning model\n",
    "    \"\"\"\n",
    "    # Load pre-trained model without top layers\n",
    "    if base_model_name == \"ResNet50\":\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif base_model_name == \"VGG16\":\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid base_model_name. Choose ResNet50 or VGG16.\")\n",
    "        \n",
    "    # Freeze base layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # Add Global Average Pooling + custom classification head\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x) # MANDATORY GAP\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(n_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=outputs)\n",
    "    \n",
    "    # Compile model (lower learning rate for fine-tuning)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create transfer learning model\n",
    "transfer_model = build_transfer_learning_model(pretrained_model_name, image_shape, n_classes)\n",
    "\n",
    "# Count layers and parameters\n",
    "frozen_layers = len([layer for layer in transfer_model.layers if not layer.trainable])\n",
    "trainable_layers = len([layer for layer in transfer_model.layers if layer.trainable])\n",
    "total_parameters = transfer_model.count_params()\n",
    "\n",
    "# Corrected trainable_parameters calculation using tf.size()\n",
    "trainable_parameters = sum(tf.size(variable).numpy() for variable in transfer_model.trainable_weights)\n",
    "\n",
    "\n",
    "print(f\"Base Model: {pretrained_model_name}\")\n",
    "print(f\"Frozen Layers: {frozen_layers}\")\n",
    "print(f\"Trainable Layers: {trainable_layers}\")\n",
    "print(f\"Total Parameters: {total_parameters:,}\")\n",
    "print(f\"Trainable Parameters: {trainable_parameters:,}\")\n",
    "print(f\"Using Global Average Pooling: YES\")\n",
    "\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6007d532",
   "metadata": {},
   "source": [
    "### 3.2 Train Transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae60dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining Transfer Learning Model...\")\n",
    "\n",
    "tl_learning_rate = 0.0001\n",
    "tl_epochs = 15 # Fine-tuning usually needs fewer epochs\n",
    "tl_batch_size = BATCH_SIZE # Use the same batch size as custom CNN for consistency\n",
    "tl_optimizer = \"Adam\"\n",
    "\n",
    "tl_start_time = time.time()\n",
    "\n",
    "history_transfer_learning = transfer_model.fit(\n",
    "    train_generator,\n",
    "    epochs=tl_epochs,\n",
    "    validation_data=test_generator,\n",
    "    steps_per_epoch=train_generator.samples // tl_batch_size,\n",
    "    validation_steps=test_generator.samples // tl_batch_size,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "tl_training_time = time.time() - tl_start_time\n",
    "\n",
    "tl_initial_loss = float(history_transfer_learning.history['loss'][0])\n",
    "tl_final_loss = float(history_transfer_learning.history['loss'][-1])\n",
    "\n",
    "print(f\"Training completed in {tl_training_time:.2f} seconds\")\n",
    "print(f\"Initial Loss: {tl_initial_loss:.4f}\")\n",
    "print(f\"Final Loss: {tl_final_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a01fcf",
   "metadata": {},
   "source": [
    "### 3.3 Evaluate Transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbb6ab7",
   "metadata": {},
   "source": [
    "print(\"\\nTransfer Learning EVALUATION\")\n",
    "\n",
    "y_pred_probs_tl = transfer_model.predict(test_generator, steps=(test_generator.samples // tl_batch_size) + 1)\n",
    "y_pred_tl = np.argmax(y_pred_probs_tl, axis=1);\n",
    "\n",
    "y_true_tl = test_generator.classes[:len(y_pred_tl)];\n",
    "\n",
    "\n",
    "tl_accuracy = float(accuracy_score(y_true_tl, y_pred_tl));\n",
    "tl_precision = float(precision_score(y_true_tl, y_pred_tl, average='macro', zero_division=0));\n",
    "tl_recall = float(recall_score(y_true_tl, y_pred_tl, average='macro', zero_division=0));\n",
    "tl_f1 = float(f1_score(y_true_tl, y_pred_tl, average='macro', zero_division=0));\n",
    "\n",
    "print(\"\\nTransfer Learning Performance:\")\n",
    "print(f\"Accuracy:  {tl_accuracy:.4f}\")\n",
    "print(f\"Precision: {tl_precision:.4f}\")\n",
    "print(f\"Recall:    {tl_recall:.4f}\")\n",
    "print(f\"F1-Score:  {tl_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795e7279",
   "metadata": {},
   "source": [
    "### 3.4 Visualize Transfer Learning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c7266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss curve\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_transfer_learning.history['loss'], label='Train Loss')\n",
    "plt.plot(history_transfer_learning.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Transfer Learning Loss Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_transfer_learning.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history_transfer_learning.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Transfer Learning Accuracy Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm_tl = confusion_matrix(y_true_tl, y_pred_tl)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_tl, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.title('Transfer Learning Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSample Transfer Learning Predictions:\")\n",
    "plot_sample_predictions(test_generator, transfer_model, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee2512c",
   "metadata": {},
   "source": [
    "### 4.1 Metrics Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e51221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON\")\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'Training Time (s)', 'Total Parameters', 'Trainable Parameters'],\n",
    "    'Custom CNN': [\n",
    "        custom_cnn_accuracy,\n",
    "        custom_cnn_precision,\n",
    "        custom_cnn_recall,\n",
    "        custom_cnn_f1,\n",
    "        custom_cnn_training_time,\n",
    "        float(custom_cnn.count_params()),\n",
    "        float(custom_cnn.count_params()) # All parameters are trainable for custom CNN\n",
    "    ],\n",
    "    'Transfer Learning': [\n",
    "        tl_accuracy,\n",
    "        tl_precision,\n",
    "        tl_recall,\n",
    "        tl_f1,\n",
    "        tl_training_time,\n",
    "        float(total_parameters),\n",
    "        float(trainable_parameters)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
